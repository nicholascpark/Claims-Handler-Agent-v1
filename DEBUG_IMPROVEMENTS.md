# Debug Improvements for Voice Agent

## Issue Identified

**Error:** `'NoneType' object has no attribute 'strip'`

**Root Cause:** The Realtime API may not always include transcripts immediately in `conversation.item.created` events. When we tried to call `.strip()` on `None`, it caused the crash.

## Fixes Applied

### 1. Added Null-Safe String Handling

**Before:**
```python
transcript = content_part.get("transcript", "").strip()
```

**After:**
```python
transcript = content_part.get("transcript")
if transcript and isinstance(transcript, str):
    transcript = transcript.strip()
```

**Applied to:**
- âœ… `conversation.item.created` handler
- âœ… `response.audio_transcript.done` handler
- âœ… `response.content_part.done` handler
- âœ… `conversation.item.input_audio_transcription.completed` handler (fallback)

### 2. Added Comprehensive Debug Logging

**Event Logging:**
```python
# Log all non-audio-delta events
if event_type not in ["response.audio.delta", "input_audio_buffer.append"]:
    print(f"[{get_timestamp()}] ğŸ“¡ Event: {event_type}")
```

**Transcript Debug Logs:**
```python
print(f"[{get_timestamp()}] ğŸ› DEBUG: conversation.item.created - item type: {item.get('type')}, role: {item.get('role')}")
print(f"[{get_timestamp()}] ğŸ› DEBUG: User message content: {len(content)} parts")
print(f"[{get_timestamp()}] ğŸ› DEBUG: Content part {idx}: type={content_type}")
print(f"[{get_timestamp()}] ğŸ› DEBUG: Transcript value: {transcript} (type: {type(transcript)})")
```

### 3. Added Fallback Event Handler

**Re-added reliable fallback:**
```python
elif event_type == "conversation.item.input_audio_transcription.completed":
    # FALLBACK: Use this event if transcript wasn't available in conversation.item.created
```

**Why:** The `conversation.item.created` event may fire before the transcript is ready. This fallback ensures we always get the user's transcript.

### 4. Enhanced Error Handling

**Added full traceback logging:**
```python
except Exception as e:
    if self._is_running:
        import traceback
        print(f"âš ï¸ WebSocket error: {e}")
        print(f"ğŸ› DEBUG: Full traceback:")
        print(traceback.format_exc())
        print(f"ğŸ› DEBUG: Last event type: {event.get('type', 'unknown') if 'event' in locals() else 'N/A'}")
```

## What You'll See Now

### Normal Flow (with debug enabled)

```
[21:08:48] ğŸ¤ Speech stopped, processing...
[21:08:48] ğŸ“¡ Event: input_audio_buffer.speech_stopped
[21:08:48] ğŸ“ Audio committed, awaiting transcript...
[21:08:48] ğŸ“¡ Event: input_audio_buffer.committed
[21:08:48] ğŸ“¡ Event: conversation.item.created
[21:08:48] ğŸ› DEBUG: conversation.item.created - item type: message, role: user
[21:08:48] ğŸ› DEBUG: User message content: 1 parts
[21:08:48] ğŸ› DEBUG: Content part 0: type=input_audio
[21:08:48] ğŸ› DEBUG: Transcript value: None (type: <class 'NoneType'>)
[21:08:48] ğŸ› DEBUG: Transcript not available yet in conversation.item.created
[21:08:49] ğŸ“¡ Event: conversation.item.input_audio_transcription.completed
[21:08:49] ğŸ‘¤ User: Hello, my name is John Smith
[EXTRACTION] âœ… Trustcall completed extraction/merge
[SUPERVISOR] ğŸ’¬ Normal response, ending turn
[21:08:50] ğŸ¤– AI: Thank you, John. What's your phone number?
```

### Error Case (if it still occurs)

```
[21:08:48] âš ï¸ WebSocket error: [specific error message]
[21:08:48] ğŸ› DEBUG: Full traceback:
Traceback (most recent call last):
  File "...", line ..., in ...
    [full stack trace]
[21:08:48] ğŸ› DEBUG: Last event type: conversation.item.created
```

## Event Flow Optimization

### Transcript Acquisition Strategy

**Primary (Fast):**
1. Try `conversation.item.created` with inline transcript âš¡ (FASTEST if available)

**Fallback (Reliable):**
2. Use `conversation.item.input_audio_transcription.completed` âœ… (RELIABLE)

**Why Both:**
- `conversation.item.created` fires immediately but transcript may be `None`
- `conversation.item.input_audio_transcription.completed` fires slightly later but always has transcript
- Deduplication logic prevents processing same transcript twice

## Testing Instructions

### 1. Run with Debug Output

```bash
python run_voice_agent.py --display-json
```

### 2. Watch for Debug Messages

Look for these patterns:
- âœ… `ğŸ“¡ Event:` - Shows all events being received
- âœ… `ğŸ› DEBUG:` - Shows detailed state information
- âœ… `ğŸ‘¤ User:` - User transcript captured successfully
- âœ… `ğŸ¤– AI:` - AI response captured successfully

### 3. Check for Errors

If you still see errors:
1. Check the full traceback
2. Note which event type caused it
3. Check if transcript is `None` or missing

### 4. Verify Transcript Flow

**Expected sequence:**
```
ğŸ“¡ Event: input_audio_buffer.speech_stopped
ğŸ“¡ Event: input_audio_buffer.committed
ğŸ“¡ Event: conversation.item.created
ğŸ› DEBUG: Transcript value: None or [actual transcript]
ğŸ“¡ Event: conversation.item.input_audio_transcription.completed  (if transcript was None)
ğŸ‘¤ User: [transcript]
```

## Performance Impact

### Debug Logging Overhead

- Event logging: ~1-2ms per event
- Debug prints: ~5-10ms total
- **Negligible impact on latency**

### To Disable Debug Logs

Comment out or remove these lines in `voice_agent.py`:
```python
# Line ~201: General event logging
if event_type not in ["response.audio.delta", "input_audio_buffer.append"]:
    print(f"[{get_timestamp()}] ğŸ“¡ Event: {event_type}")

# Lines ~274-287: Detailed conversation.item.created debugging
# (Keep the null-safe handling, just remove the print statements)
```

## Key Improvements

1. âœ… **Null-Safe:** All `.strip()` calls now check for `None` and type first
2. âœ… **Visible:** All events and transcript values are logged
3. âœ… **Reliable:** Fallback event handler ensures transcripts are never missed
4. âœ… **Debuggable:** Full traceback on any error
5. âœ… **Resilient:** Agent continues working even if one transcript method fails

## Monitoring Checklist

When running the agent, verify:

- [ ] All events are logged with `ğŸ“¡ Event:` prefix
- [ ] User transcripts appear with `ğŸ‘¤ User:` prefix
- [ ] AI responses appear with `ğŸ¤– AI:` prefix
- [ ] No `NoneType` errors in logs
- [ ] Transcripts are captured (even if via fallback)
- [ ] LangGraph workflow triggers after each user message

## Next Steps if Issues Persist

If you still encounter the `NoneType` error:

1. **Share the full debug output** including:
   - All `ğŸ“¡ Event:` lines
   - All `ğŸ› DEBUG:` lines
   - The full traceback

2. **Check Azure OpenAI Service:**
   - Verify Realtime API version is supported
   - Check deployment configuration
   - Ensure API key is valid

3. **Test with different inputs:**
   - Short utterances (1-2 words)
   - Long utterances (full sentences)
   - Multiple speakers
   - Background noise

## Summary

The fixes ensure:
- âœ… No crashes from `None` transcripts
- âœ… Full visibility into event flow
- âœ… Reliable transcript capture via fallback
- âœ… Better error messages for debugging
- âœ… Maintained performance optimization

**Status:** Ready for testing with comprehensive debugging enabled.

